{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/gpfs/workdir/liashuhamy/clr',\n",
       " '/gpfs/users/liashuhamy/.conda/envs/pcamenv/lib/python37.zip',\n",
       " '/gpfs/users/liashuhamy/.conda/envs/pcamenv/lib/python3.7',\n",
       " '/gpfs/users/liashuhamy/.conda/envs/pcamenv/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/gpfs/users/liashuhamy/.local/lib/python3.7/site-packages',\n",
       " '/gpfs/users/liashuhamy/.conda/envs/pcamenv/lib/python3.7/site-packages',\n",
       " '/gpfs/users/liashuhamy/.conda/envs/pcamenv/lib/python3.7/site-packages/locket-0.2.1-py3.7.egg',\n",
       " '/gpfs/users/liashuhamy/.conda/envs/pcamenv/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/gpfs/users/liashuhamy/.ipython']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.sys.path.append('/gpfs/users/liashuhamy/.conda/envs/pcamenv/lib/python3.7/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul 16 21:58:54 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100S-PCI...  On   | 00000000:2F:00.0 Off |                    0 |\r\n",
      "| N/A   34C    P0    26W / 250W |      0MiB / 32510MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "import matplotlib.pyplot as plt\n",
    "# from imutils import paths\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "# import seaborn as sns\n",
    "import numpy as np\n",
    "# import cv2\n",
    "\n",
    "# Random seed fixation\n",
    "tf.random.set_seed(666)\n",
    "np.random.seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h5py\n",
    "\n",
    "# X_train = h5py.File('/gpfs/workdir/liashuhamy/camel/raw/pre_9_patient_split_vahadane/camelyonpatch_level_2_split_train_x.h5', 'r')['x'][:]\n",
    "# y_train = h5py.File('/gpfs/workdir/liashuhamy/camel/raw/pre_9_patient_split_vahadane/camelyonpatch_level_2_split_train_y.h5', 'r')['y'][:].reshape((-1,1))\n",
    "\n",
    "# X_test = h5py.File('/gpfs/workdir/liashuhamy/camel/raw/pre_9_patient_split_vahadane/camelyonpatch_level_2_split_valid_x.h5', 'r')['x'][:]\n",
    "# y_test = h5py.File('/gpfs/workdir/liashuhamy/camel/raw/pre_9_patient_split_vahadane/camelyonpatch_level_2_split_valid_y.h5', 'r')['y'][:].reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# def resize(img, size):\n",
    "#     img = Image.fromarray(img)\n",
    "#     img = img.resize(size)\n",
    "#     return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# new_x = []\n",
    "# from tqdm import tqdm\n",
    "# for i in tqdm(range(X_train.shape[0])):\n",
    "#     new_x.append(cv2.resize(X_train[i], (224, 224)))\n",
    "# X_train = np.array(new_x)\n",
    "\n",
    "# new_x = []\n",
    "# from tqdm import tqdm\n",
    "# for i in tqdm(range(X_test.shape[0])):\n",
    "#     new_x.append(cv2.resize(X_test[i], (224, 224)))\n",
    "# X_test = np.array(new_x)\n",
    "\n",
    "# X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train / 255.\n",
    "# X_test = X_test / 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, preprocess_input = Classifiers.get('resnet18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[0][:10,:10, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_input(X_train[0])[:10,:10, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data load is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "import tensorflow_io as tfio\n",
    "X_train = tfio.IODataset.from_hdf5('/gpfs/workdir/shared/cpm4c/CAMELYON/prepared_datasets/pre_10_vahadane/camelyonpatch_level_2_split_train_x.h5', dataset='/x')\n",
    "y_train = h5py.File('/gpfs/workdir/shared/cpm4c/CAMELYON/prepared_datasets/pre_10_vahadane/camelyonpatch_level_2_split_train_y.h5', 'r')['y'][:].reshape((-1,1))\n",
    "X_test = tfio.IODataset.from_hdf5('/gpfs/workdir/shared/cpm4c/CAMELYON/prepared_datasets/pre_10_vahadane/camelyonpatch_level_2_split_valid_x.h5', dataset='/x')\n",
    "y_test = h5py.File('/gpfs/workdir/shared/cpm4c/CAMELYON/prepared_datasets/pre_10_vahadane/camelyonpatch_level_2_split_valid_y.h5', 'r')['y'][:].reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "import tensorflow_io as tfio\n",
    "X_train = tfio.IODataset.from_hdf5('/gpfs/workdir/liashuhamy/camel/raw/pre_9_patient_split_vahadane/camelyonpatch_level_2_split_train_x.h5', dataset='/x')\n",
    "y_train = h5py.File('/gpfs/workdir/liashuhamy/camel/raw/pre_9_patient_split_vahadane/camelyonpatch_level_2_split_train_y.h5', 'r')['y'][:].reshape((-1,1))\n",
    "X_test = tfio.IODataset.from_hdf5('/gpfs/workdir/liashuhamy/camel/raw/pre_9_patient_split_vahadane/camelyonpatch_level_2_split_valid_x.h5', dataset='/x')\n",
    "y_test = h5py.File('/gpfs/workdir/liashuhamy/camel/raw/pre_9_patient_split_vahadane/camelyonpatch_level_2_split_valid_y.h5', 'r')['y'][:].reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95106, 47553, 47553.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[0], y_train.sum(), y_train.shape[0] - y_train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30296, 15148, 15148.0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape[0], y_test.sum(), y_test.shape[0] - y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.map(lambda x: tf.image.resize(x, [112,112]))\n",
    "X_train = X_train.map(lambda x: tf.cast(x,tf.float32)/255.)\n",
    "X_train = X_train.map(lambda x: (x - mean)/std)\n",
    "X_train = (\n",
    "    X_train\n",
    "    .batch(33)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.map(lambda x: tf.image.resize(x, [112,112]))\n",
    "X_test = X_test.map(lambda x: tf.cast(x,tf.float32)/255.)\n",
    "X_test = X_test.map(lambda x: (x - mean)/std)\n",
    "X_test = (\n",
    "    X_test\n",
    "    .batch(28)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/liashuhamy/.conda/envs/pcamenv/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_enc = np.array([[1-i, i] for i in y_train]).reshape((-1,2))\n",
    "y_test_enc = np.array([[1-i, i] for i in y_test]).reshape((-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((95106, 2), (30296, 2))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_enc.shape, y_test_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1]], dtype=uint8),\n",
       " array([[0],\n",
       "        [1],\n",
       "        [1]], dtype=uint8))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_enc[:3], y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_models.tfkeras import Classifiers\n",
    "from tensorflow import keras\n",
    "def get_resnet_simclr(hidden_1, hidden_2, hidden_3):\n",
    "    ResNet18, preprocess_input = Classifiers.get('resnet18')#keras.models.load_model('resnet18.h5')\n",
    "    base_model = keras.models.load_model('resnet18.h5')#ResNet18(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    base_model.trainable = True\n",
    "    inputs = Input((224, 224, 3))\n",
    "    h = base_model(inputs, training=False)\n",
    "    h = GlobalAveragePooling2D()(h)\n",
    "\n",
    "    projection_1 = Dense(hidden_1)(h)\n",
    "    projection_1 = Activation(\"relu\")(projection_1)\n",
    "    projection_2 = Dense(hidden_2)(projection_1)\n",
    "#     projection_2 = Activation(\"relu\")(projection_2)\n",
    "#     projection_3 = Dense(hidden_3)(projection_2)\n",
    "\n",
    "    resnet_simclr = Model(inputs, projection_2)\n",
    "\n",
    "    return resnet_simclr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "model_1 (Functional)         (None, 7, 7, 512)         11186112  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "=================================================================\n",
      "Total params: 11,383,232\n",
      "Trainable params: 8,590,848\n",
      "Non-trainable params: 2,792,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "resnet_simclr = get_resnet_simclr(256,256,256)\n",
    "resnet_simclr = keras.models.load_model('model_sgd_augm_wfreez_112.h5')\n",
    "\n",
    "resnet_simclr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(H):\n",
    "\twith plt.xkcd():\n",
    "# \t\tplt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
    "# \t\tplt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
    "\t\tplt.plot(H.history[\"accuracy\"], label=\"train_acc\")\n",
    "\t\tplt.plot(H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "\t\tplt.title(\"Training Accuracy\")\n",
    "\t\tplt.xlabel(\"Epoch #\")\n",
    "\t\tplt.ylabel(\"Accuracy\")\n",
    "\t\tplt.legend(loc=\"lower left\")\n",
    "\t\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_linear_model(features):\n",
    "    linear_model = Sequential([Dense(2, input_shape=(features, ), activation=\"softmax\")])\n",
    "    return linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pad (ZeroPadding2D)             (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9408        pad[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 112, 112, 64) 0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pad1 (ZeroPadding2D)            (None, 114, 114, 64) 0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "maxpool (MaxPooling2D)          (None, 56, 56, 64)   0           pad1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "layer1.0.conv1 (Conv2D)         (None, 56, 56, 64)   36864       maxpool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer1.0.bn1 (BatchNormalizatio (None, 56, 56, 64)   256         layer1.0.conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 56, 56, 64)   0           layer1.0.bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer1.0.conv2 (Conv2D)         (None, 56, 56, 64)   36864       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer1.0.bn2 (BatchNormalizatio (None, 56, 56, 64)   256         layer1.0.conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 56, 56, 64)   0           maxpool[0][0]                    \n",
      "                                                                 layer1.0.bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 56, 56, 64)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "layer1.1.conv1 (Conv2D)         (None, 56, 56, 64)   36864       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer1.1.bn1 (BatchNormalizatio (None, 56, 56, 64)   256         layer1.1.conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           layer1.1.bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer1.1.conv2 (Conv2D)         (None, 56, 56, 64)   36864       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer1.1.bn2 (BatchNormalizatio (None, 56, 56, 64)   256         layer1.1.conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 64)   0           activation_1[0][0]               \n",
      "                                                                 layer1.1.bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer2.0.pad (ZeroPadding2D)    (None, 58, 58, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer2.0.conv1 (Conv2D)         (None, 28, 28, 128)  73728       layer2.0.pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer2.0.bn1 (BatchNormalizatio (None, 28, 28, 128)  512         layer2.0.conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 28, 28, 128)  0           layer2.0.bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer2.0.downsample.0 (Conv2D)  (None, 28, 28, 128)  8192        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer2.0.conv2 (Conv2D)         (None, 28, 28, 128)  147456      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer2.0.downsample.1 (BatchNor (None, 28, 28, 128)  512         layer2.0.downsample.0[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer2.0.bn2 (BatchNormalizatio (None, 28, 28, 128)  512         layer2.0.conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 28, 28, 128)  0           layer2.0.downsample.1[0][0]      \n",
      "                                                                 layer2.0.bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 28, 28, 128)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer2.1.conv1 (Conv2D)         (None, 28, 28, 128)  147456      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer2.1.bn1 (BatchNormalizatio (None, 28, 28, 128)  512         layer2.1.conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 28, 28, 128)  0           layer2.1.bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer2.1.conv2 (Conv2D)         (None, 28, 28, 128)  147456      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer2.1.bn2 (BatchNormalizatio (None, 28, 28, 128)  512         layer2.1.conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 128)  0           activation_5[0][0]               \n",
      "                                                                 layer2.1.bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 28, 28, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer3.0.pad (ZeroPadding2D)    (None, 30, 30, 128)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer3.0.conv1 (Conv2D)         (None, 14, 14, 256)  294912      layer3.0.pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer3.0.bn1 (BatchNormalizatio (None, 14, 14, 256)  1024        layer3.0.conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 14, 14, 256)  0           layer3.0.bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer3.0.downsample.0 (Conv2D)  (None, 14, 14, 256)  32768       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer3.0.conv2 (Conv2D)         (None, 14, 14, 256)  589824      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer3.0.downsample.1 (BatchNor (None, 14, 14, 256)  1024        layer3.0.downsample.0[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer3.0.bn2 (BatchNormalizatio (None, 14, 14, 256)  1024        layer3.0.conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 14, 14, 256)  0           layer3.0.downsample.1[0][0]      \n",
      "                                                                 layer3.0.bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 14, 14, 256)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer3.1.conv1 (Conv2D)         (None, 14, 14, 256)  589824      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer3.1.bn1 (BatchNormalizatio (None, 14, 14, 256)  1024        layer3.1.conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 14, 14, 256)  0           layer3.1.bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer3.1.conv2 (Conv2D)         (None, 14, 14, 256)  589824      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer3.1.bn2 (BatchNormalizatio (None, 14, 14, 256)  1024        layer3.1.conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 14, 14, 256)  0           activation_9[0][0]               \n",
      "                                                                 layer3.1.bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 14, 14, 256)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer4.0.pad (ZeroPadding2D)    (None, 16, 16, 256)  0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer4.0.conv1 (Conv2D)         (None, 7, 7, 512)    1179648     layer4.0.pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer4.0.bn1 (BatchNormalizatio (None, 7, 7, 512)    2048        layer4.0.conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 7, 7, 512)    0           layer4.0.bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer4.0.downsample.0 (Conv2D)  (None, 7, 7, 512)    131072      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer4.0.conv2 (Conv2D)         (None, 7, 7, 512)    2359296     activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer4.0.downsample.1 (BatchNor (None, 7, 7, 512)    2048        layer4.0.downsample.0[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer4.0.bn2 (BatchNormalizatio (None, 7, 7, 512)    2048        layer4.0.conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 7, 7, 512)    0           layer4.0.downsample.1[0][0]      \n",
      "                                                                 layer4.0.bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 7, 7, 512)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer4.1.conv1 (Conv2D)         (None, 7, 7, 512)    2359296     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer4.1.bn1 (BatchNormalizatio (None, 7, 7, 512)    2048        layer4.1.conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 7, 7, 512)    0           layer4.1.bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer4.1.conv2 (Conv2D)         (None, 7, 7, 512)    2359296     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer4.1.bn2 (BatchNormalizatio (None, 7, 7, 512)    2048        layer4.1.conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 7, 7, 512)    0           activation_13[0][0]              \n",
      "                                                                 layer4.1.bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 7, 7, 512)    0           add_7[0][0]                      \n",
      "==================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 11,186,112\n",
      "Trainable params: 8,393,728\n",
      "Non-trainable params: 2,792,384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_simclr.layers[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 pad\n",
      "2 conv1\n",
      "3 bn1\n",
      "4 relu\n",
      "5 pad1\n",
      "6 maxpool\n",
      "7 layer1.0.conv1\n",
      "8 layer1.0.bn1\n",
      "9 activation\n",
      "10 layer1.0.conv2\n",
      "11 layer1.0.bn2\n",
      "12 add\n",
      "13 activation_1\n",
      "14 layer1.1.conv1\n",
      "15 layer1.1.bn1\n",
      "16 activation_2\n",
      "17 layer1.1.conv2\n",
      "18 layer1.1.bn2\n",
      "19 add_1\n",
      "20 activation_3\n",
      "21 layer2.0.pad\n",
      "22 layer2.0.conv1\n",
      "23 layer2.0.bn1\n",
      "24 activation_4\n",
      "25 layer2.0.downsample.0\n",
      "26 layer2.0.conv2\n",
      "27 layer2.0.downsample.1\n",
      "28 layer2.0.bn2\n",
      "29 add_2\n",
      "30 activation_5\n",
      "31 layer2.1.conv1\n",
      "32 layer2.1.bn1\n",
      "33 activation_6\n",
      "34 layer2.1.conv2\n",
      "35 layer2.1.bn2\n",
      "36 add_3\n",
      "37 activation_7\n",
      "38 layer3.0.pad\n",
      "39 layer3.0.conv1\n",
      "40 layer3.0.bn1\n",
      "41 activation_8\n",
      "42 layer3.0.downsample.0\n",
      "43 layer3.0.conv2\n",
      "44 layer3.0.downsample.1\n",
      "45 layer3.0.bn2\n",
      "46 add_4\n",
      "47 activation_9\n",
      "48 layer3.1.conv1\n",
      "49 layer3.1.bn1\n",
      "50 activation_10\n",
      "51 layer3.1.conv2\n",
      "52 layer3.1.bn2\n",
      "53 add_5\n",
      "54 activation_11\n",
      "55 layer4.0.pad\n",
      "56 layer4.0.conv1\n",
      "57 layer4.0.bn1\n",
      "58 activation_12\n",
      "59 layer4.0.downsample.0\n",
      "60 layer4.0.conv2\n",
      "61 layer4.0.downsample.1\n",
      "62 layer4.0.bn2\n",
      "63 add_6\n",
      "64 activation_13\n",
      "65 layer4.1.conv1\n",
      "66 layer4.1.bn1\n",
      "67 activation_14\n",
      "68 layer4.1.conv2\n",
      "69 layer4.1.bn2\n",
      "70 add_7\n",
      "71 activation_15\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(resnet_simclr.layers[1].layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "model_1 (Functional)         (None, 7, 7, 512)         11186112  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "=================================================================\n",
      "Total params: 11,383,232\n",
      "Trainable params: 197,120\n",
      "Non-trainable params: 11,186,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_simclr.layers[1].trainable = False\n",
    "resnet_simclr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder model with non-linear projections\n",
    "projection = Model(resnet_simclr.input, resnet_simclr.layers[-2].output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = projection.layers[1].layers[2].get_weights()[0]\n",
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters = (filters - f_min) / (f_max - f_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.44786358, 0.4473378 , 0.45237353],\n",
       "        [0.45016688, 0.43915337, 0.44853982],\n",
       "        [0.45249277, 0.43484026, 0.46486968],\n",
       "        [0.49370635, 0.4732586 , 0.5017252 ],\n",
       "        [0.48390633, 0.47095144, 0.50141406],\n",
       "        [0.46265116, 0.4538219 , 0.47156158],\n",
       "        [0.44664064, 0.43962416, 0.4426577 ]],\n",
       "\n",
       "       [[0.45942476, 0.47803047, 0.46174508],\n",
       "        [0.4585886 , 0.47153363, 0.44343922],\n",
       "        [0.39436066, 0.39726388, 0.38576826],\n",
       "        [0.3026471 , 0.28740293, 0.2945677 ],\n",
       "        [0.30762768, 0.28542668, 0.31720746],\n",
       "        [0.38406527, 0.3671651 , 0.3836758 ],\n",
       "        [0.45547804, 0.45277622, 0.43842414]],\n",
       "\n",
       "       [[0.44973257, 0.45301563, 0.4587595 ],\n",
       "        [0.4852366 , 0.50638396, 0.47983718],\n",
       "        [0.6123398 , 0.6696682 , 0.5701382 ],\n",
       "        [0.76918745, 0.86766326, 0.6847196 ],\n",
       "        [0.73290664, 0.83408076, 0.6409633 ],\n",
       "        [0.5912854 , 0.6517993 , 0.50956285],\n",
       "        [0.4876473 , 0.5204355 , 0.46336594]],\n",
       "\n",
       "       [[0.46986744, 0.45032433, 0.4676746 ],\n",
       "        [0.4174318 , 0.3843119 , 0.43949163],\n",
       "        [0.29301697, 0.22726227, 0.34755138],\n",
       "        [0.21760008, 0.13478552, 0.3093361 ],\n",
       "        [0.30783454, 0.2476171 , 0.39688048],\n",
       "        [0.45313635, 0.43066484, 0.49571496],\n",
       "        [0.48443708, 0.4865694 , 0.518403  ]],\n",
       "\n",
       "       [[0.438661  , 0.42339584, 0.43821943],\n",
       "        [0.4620929 , 0.45065704, 0.46336138],\n",
       "        [0.4924985 , 0.4680264 , 0.5065061 ],\n",
       "        [0.42437664, 0.37196115, 0.48639402],\n",
       "        [0.2745004 , 0.20517673, 0.39034265],\n",
       "        [0.22733209, 0.14655824, 0.31495857],\n",
       "        [0.3148448 , 0.2569331 , 0.37039104]],\n",
       "\n",
       "       [[0.46992552, 0.4711341 , 0.46463144],\n",
       "        [0.47548896, 0.4833469 , 0.4520525 ],\n",
       "        [0.48725867, 0.5070559 , 0.43312848],\n",
       "        [0.58195555, 0.62452626, 0.48435563],\n",
       "        [0.67597795, 0.74723345, 0.58326745],\n",
       "        [0.6650896 , 0.7130356 , 0.5843627 ],\n",
       "        [0.5427516 , 0.5602886 , 0.51688886]],\n",
       "\n",
       "       [[0.44608024, 0.45631826, 0.4538674 ],\n",
       "        [0.4514901 , 0.45706496, 0.4538835 ],\n",
       "        [0.44051626, 0.4441886 , 0.44806203],\n",
       "        [0.41804525, 0.41593298, 0.42381158],\n",
       "        [0.37243825, 0.37376925, 0.37354037],\n",
       "        [0.40925282, 0.4119311 , 0.3902692 ],\n",
       "        [0.45035657, 0.45385394, 0.43284604]]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 64 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "figure, axes = plt.subplots(nrows=8, ncols=8)\n",
    "\n",
    "i = 0\n",
    "for x in range(8):\n",
    "    for y in range(8):\n",
    "        axes[x, y].imshow(filters[:, :, :, i])\n",
    "        \n",
    "        axes[x, y].axis('off')\n",
    "        i = i + 1\n",
    "# axes[0, 1].imshow(filters[:, :, :, 1])\n",
    "# axes[1, 0].imshow(filters[:, :, :, 2])\n",
    "# axes[1, 1].imshow(filters[:, :, :, 3])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARUAAADrCAYAAABHAQI/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAV7UlEQVR4nO3dWWyc1fnH8d/MeMl4S5zYIbGz74QUhUWAKLRREYJSkFBCggQXXFTiokLior2o2qrctBJCiDsk4AK4QQREIQpIKOmilKWsKRGQhKCQDWd1VhsvcTzz/i+ic3zOGXviNzmeof5/P1KlY57x+G2O5/HZTyZJEgFALNlqPwCAyYWkAiAqkgqAqEgqAKIiqQCIiqQCIKqaNC/O5/NJc3PzqLFMJmPLuVzOi7nT1sVicdRYb2+vBgYGMkLF5fP5pKWlRZJfV6Fsduy/QeH3Ua/VN2XKlDE/r25d1tbWjvkew8PDo379ww8/aHBwcNR6TZVUmpub9cADD5Q8VPj1jBkzvNiFCxdsub+/34sNDg5Kkt544400j4KIWlpa9OCDD0oq/SVyk4VJPKPFhoaGvJj5mnqtnubmZq1bt05S6R/zhoYGW541a9aY73Hq1KlRv968efOY35MqqWQyGdXX10sq/ct06NAhW966dWvJ9xlLly71YgsXLix5DSorm83aX7Lwl+/IkSO2/Pnnn4/5HnPnzvW+njdvniTqtZqy2azq6uokXWxZuNy6/PDDD72Y+8dj1apVXmzJkiWX/rmpnxQAyiCpAIiKpAIgqlRjKkmS2EHX1tZWL/boo4/a8t133+3Fzp49a8v/+te/vNiOHTsklc4YoXKKxaIdMJ8+fboXe+SRR2z5zjvv9GJuP33btm1e7KuvvpJUfmYBEytJEjtGFg7Grl271pbvvfdeL9bV1WXLr7/+uhc7ePCgpPKfV1oqAKIiqQCIKlX3x516PHDggBd79dVXbfm7777zYitWrLDlsAk9nkVXmHjm33/Xrl3ef3/ppZdsOazz5cuX2/KaNWu8mOlGFQqFiE+JNDKZjJ1SdpcGSNLjjz9uyxs2bPBit956qy2H9WqmlM3SktHQUgEQFUkFQFQkFQBRZdKMZbS3tydmKqqxsdGLuUt7w7733//+d1s+ceKEFzPjLXv37mXjWZW0t7cn999/vyR/T4gk2yeXSsfKPvroI1s+efKkF1u2bJkkad++fdRrlbS1tSW/+tWvJEnTpk3zYu62ip6eHi/273//25a/+OILL7Z48WJJ0p49e9Tf3z9qvdJSARAVSQVAVKmmlHO5nKZOnSqp9OgDd3frPffc48V+97vf2XK4td40oZ988sk0j4KIcrmcXSFdU+P/SuTzeVt+6KGHvNhf/vIXWw53wX766aeSpKeeeirqs2L83Ho1K6aN//73v7ZsujTGE088YcvhLnOzUvrpp58e8+fSUgEQFUkFQFQkFQBRpRpTKRaLtu8c7lJ0dyK/8847XuzFF1+05XB3c1tbmyRpYGAgzaMgInf3uXv0p3TxjFlj//79Xmzjxo22HJ6Fasbezp8/H/VZMX5Jkth//3BsxF0S8s0333ixd999d9TXSVJnZ6ckqa+vb8yfS0sFQFQkFQBRpVpRm8lkuiUdnKBnmZ8kSfsEvTfKoF4np2rVa6qkAgCXQvcHQFQkFQBRkVQARJVqnUpDQ0MSbqE23L1A4S137tqHcM+Qezfr+fPn2SJfBY2NjYlZPxSuZ3DrK6w7dzwuHJsz9Xr27Fn19fVRr1Xg3pEdcteZhfu9XOFxoGbdS7S7lKdNm2av4gh/+dxzN8LNS4cPH7blcDFNd3e3JGnLli1pHgURtba26rHHHpNUeqWGu6gtPJfU/WMR/vIdP35ckvT8889HfVaMX0tLix5++OFRY+7n0CxAHU24yG3v3r2SIt6l3NDQoNWrV0sq/at11VVX2bK5R9eYPXu2LYd/0c6cOSNJ+sUvfpHmURBRLpezB1WHhzTNmTPHlsN7dN1YuHL26NGjkrigvZpqa2vtZy/8Y9HR0WHL5jNtmAO2JH+lvDRyANvHH3885s9lTAVAVCQVAFGRVABElWpMpb+/354YNWXKFC/mHp4bHm7tDuKGs0cLFiyQxGVi1TQ4OGgvETO7iw23T33s2DEv5vbLm5qavJipcy4Tq57BwUHt3r1bUunnzp1MCWdrT506Zcvh6QFmLLVcvdJSARAVSQVAVKm6PwMDA/r6668ljUwFG+3tIxsW9+3b58XcO2FWrlzpxe677z5JpVNXqJzBwUHt2bNHkn8ok+R3c8M6cg/FXrRokRcz05ThnTKonAsXLtip/a6uLi/mDkn885//9GLueiSz1MC45pprJHFIE4AKIqkAiIqkAiCqVGMqtbW19uDbTz75xIu5lxOF/Wh36fe3337rxd5//31JpZdRoXJqamrsgeQ7d+70Yu70Yn9/vxdzp5/D8RYzTRl+Dyonl8vZqf4PPvjAi5m9WVLpco5Zs2bZcjgVbT6njKkAqBiSCoCoUnV/8vm8nVIKV9S6uyDDO4HcVXnhXcpDQ0Ojfg8qp6mpST//+c8ljaxwNtwp5vBIC7cu3ellaeT3o9xZHZhYbr26XRrJX/Uedn/c6eZwta0ZyihXr7RUAERFUgEQFUkFQFSpOryZTMaOnYTLsmfOnGnL4Q5Gd7ox7Hub4yTDowpROTU1NXY5dni0oNu/DqeH3WnFsI9txtHCsTdUTn19vR0jC3efuyf1hcs53GNCwzFQU6/hSXIuWioAoiKpAIiKu5RBvU5S3KUMYFKg+wMgKpIKgKhSTSnncrmk3FSSEV4sVY6ZSr5w4YIKhQLXY1ZBJpOZ0D5wkiTUaxW49VruFsLL0dvbG+fa09raWs2dO/eSrzNXI46Heb/vv/8+zaMASGHt2rVR3+/NN98cM0b3B0BUqVoqU6dO1S9/+ctLvu7dd98d93ua93vttdfSPAoiamho0NVXXy1JevTRR73YCy+8cFnvad7nr3/965U9HC7bvHnz9Mc//lGSdMMNN4z7+7Zv3z5mzLyPOVxtNLRUAERFUgEQFUkFQFSpxlTq6+u1dOnSqA9g3o9dytXT1tZmx0DCvvfzzz9vy+X62iHzPo2NjRGeEJejsbHR1kO5MZWwXsu91sTcw+xDtFQAREVSARBVRU4lHs8Uc5pVuJg4abo45aabTXeq3P0wqJw09Tqe9yl3nxMtFQBRkVQAREVSARBV6inlJUuWjBpzNxGWm3ZOs4QfleFOPZYTq1+Oygvrt1xdjmeZfjm0VABERVIBEFW0KeVyu5fdLtNYr6Nb9OMwntWU43mtwYraH4fLWQ19uWipAIiKpAIgKpIKgKgmZJl+OO3sfj3W+bXcufvjcDk7Vst9X7ndrJhYfX19Y46lXO64CbuUAVQcSQVAVNylDOp1kuIuZQCTAt0fAFGRVABElWpKubW1Neno6JAkFQoFL5bNZkctS1JNzciPGRoa8mKZzMXrWI8cOaIzZ85w524VTJ8+Pens7JR08U5rl1uXpq6MXC5ny+Hvg3nt4cOHqdcqqaurS8xSjbq6Oi/mLuEIp4fz+bwtDw8Pe7GBgQFJUnd3t3p7e6/8LuWOjg5t3LhRknTu3Dkv1tTUNOoDS9L06dNtuaury4uZX8yHHnoozaMgos7OTr311luSpGPHjnkx9xcu/MV067y3t9eLmdeuW7cu6rNi/KZMmaKbb75Z0sU6di1fvtyWwzUrP/nJT2z5xIkTXmznzp2SpD/96U9j/txUSWVoaEgHD44+mDxz5kxbDi9bf+6552y5ubnZi911112SSv/SoXKy2axNHu3t/oC+e3XKrl27vNjWrVttef78+V7MXAgetlpROS0tLbrjjjskSddcc40Xu+6662w5PB96y5Yttrxs2TIvZv74P/PMM2P+XGocQFQkFQBRkVQARJVqTKVYLNr7PmbPnu3F9u3bZ8svv/yyF9u0aZMth/231atXSyqddUDlFAoFnT17VlLpTMDu3btt2R0bk6S3337blltbW72Y6cMPDg7GfFSkkCSJnW0NJ08++OADW3711Ve92ObNm2152rRpXswM6IcD8y5aKgCiIqkAiCpV96fc1KPb/A3PoW1ra7PlcFrSNJPdBTeorCRJVCwWJZUucHOnlBctWuTFTNd1NKZ7XFtbG+kpkVYmk7H//qZ+Dbf7MmPGDC82d+5cWw7Xo5nubLk9g7RUAERFUgEQFUkFQFSpxlQKhYJ6enokjWwsMtzl2D/96U+92KxZs2zZbEg0zL4gd9MhKstdKjBazLj99tu9mLs1w0xJG1dddZUkxlSqqVAo2DGRQ4cOebHTp0/b8i233OLF3GUFR44c8WLz5s2TVLoPzEVLBUBUJBUAUaXqc+Tzea1atUpS6a7H48eP23LYxVmwYIEthytxTTMqnMpE5dTV1WnOnDmS/Clkye/mut1YSVq6dKkthyulTdeIbm31FItFWy/hCtju7m5bDldDr1ixwpYXLlzoxczvQzhF7aKlAiAqkgqAqEgqAKK67CnlcIrK3aUcTi+6S/D7+vq8mBmLYZdy9SRJYv/9wxP4wqUDLne6ONxmYX5PONGvepIkscvqw8+dqZ/RYu6UsntkqDSybL9cvdJSARAVSQVAVFx7Cup1kuLaUwCTAt0fAFGRVABERVIBEFWqdSqZTGZCB2CSJGEDUBVQr5NTteqVlgqAqEgqAKIiqQCIiqQCICqSCoCoSCoAoiKpAIiKpAIgKpIKgKhIKgCiIqkAiIqkAiAqkgqAqEgqAKIiqQCIiqQCICqSCoCoSCoAoiKpAIiKpAIgKpIKgKhIKgCiSnVFh6STmsC7WSfofXFp1OvkVJV65S5lAFHR/QEQFUkFQFQkFQBRpRqozefzSXNzsySptrbWixWLRVsuFApezP06l8t5sUzm4nWsPT09GhgY4M7dKmhqakpmzJghSTp9+rQXa21tteUpU6aE32fLFy5c8GLnz5+XJB0/flznzp2jXqugqakpMfUX1k/4OXTV1IykheHhYS9mPq9nzpxRX1/fqPWaKqk0Nzdr3bp1kqSOjg4vNjAwYMu9vb1e7Ny5c7bc2Njoxerq6iRJGzduTPMoiGjGjBn6wx/+IKm0Hkx9S9KSJUu82G233WbLR48e9WIHD16cdPjNb34T9Vkxfq2trfrtb38rSTpy5IgXa2lpseVwsqa9vd2WT5w44cVMY+LZZ58d8+emSiq1tbXq7OyUJK1cudKLuQ+9a9cuL7Zz585RH1ga+T8XZlJUTpIkGhwclCQtXLjQi+3YscOW77rrLi/23nvv2fLdd9/txerr6yWVtm5QOYVCQWfOnJEk7du3z4uZHockrV692ouZz7gkrVixwoudPXtWUvl6ZUwFQFQkFQBRkVQARJV2mb4d1Fm0aJH3393R5D179nixrq4uW/7hhx+82OzZsyUxplJNhULBDqaHM3fvv/++Lf/5z3/2YtOnT/few2VmkcLZA1ROoVCwYyDfffedF3NneK699lovtmzZMlsOZ3nNhIyZBRoNLRUAUZFUAESVqvuTJIltzs6ZM8eLufPeH3/8sRdz16mEi6tMM4xmcvUMDw/bevn++++9mLtO4csvv/Rid9xxhy2H61TMNGVDQ0PMR0UK2WxW+XxeknTo0CEvNjQ0ZMunTp3yYsuXLx/zPU03lyllABVDUgEQFUkFQFSpxlSKxaJdzh2OgbhTzDNnzvRi7pLgkydPerG+vj773qiO+vp6u6/njTfe8GJr16615S1btngxd2n+P/7xDy/2s5/9TNLIxkJUXjabtWNa7t688OuvvvrKi7ljoGZMJvyaKWUAFUNSARBV6u6POdYg3PXortCbO3euF1u1apUtu6trpZGpqePHj6d5FETU0NCg66+/XpJ0+PBhL+Z+bbo0hjtNuWDBAi9mdqO7vxeorJqaGjsUMX++f071sWPHbDlc5vHZZ5/Z8qxZs7yYe4bOWGipAIiKpAIgKpIKgKhSL9M3U7/h8XTulHA26+cqt78dHidpTqYqd2YmJtbw8LCd6nd3qEr+sn13qlGS3nnnHVu++uqrvRi7lKsvk8nYMa2lS5d6MXdbTThOsn37dlsOTyMwYzPlThWgpQIgKpIKgKhSXXuayWS6NYF3syZJ0n7plyE26nVyqla9cpcygKjo/gCIiqQCIKpUU8qZTCYx08XlpoDDmNvFCncju1NTSZJwPWYVtLW1JWbaP6wf90DrcjvJwzo3U5kHDhzQyZMnqdcqyGQy9oNnLncbTXi4tbskJFwSYD6vw8PDKhaLV37taTabtXt13Dt2JX8rdDjv7T5Yf3+/FwvXu6DyFixYoM8//1xS6ZW1bn2FNyG4SWbatGlezNzNfNNNN8V8VFymcG+W+4c+3N/jriXr7u72YmYvWHiEiYvuD4CoUm8hNc3ccHWlm93CFbVu09gc8mSYFg6zUNXjHnwdthx7enps+cCBAyXfZ4QtFbPClkOaqiefz9tDrMM7kd2D683dW4Z7n9PBg/6MtGmpvPXWW2P+XFoqAKIiqQCIiqQCIKq0U8p2+imcopo6daoth5cRubNBu3fv9mLmsir3JCpUVrFYtLM85u5dY//+/bZsZogM90Kqzs5OL2bq3H0Nqiec4bnuuutsed68eV7MHVNxy9LI5XDlpqhpqQCIiqQCIKpU3Z9cLmenDjs6OryY27z69a9/7cXc6atNmzZ5sVdeeUVS6TQ0KidJEnsPjHt3siT95z//seVt27Z5MffuGLc5LY00k8PFjqicmpoauwhx8eLFXszt1oSHYrsH17e1tXkxs+CRu5QBVAxJBUBUJBUAUaW+TMxsKgunHtesWWPL5mIqw71b+cMPP/RiZoyGg6+rJ0kSuxs53H7h7iI/evSoF3NfGy71Nkv42X5RPZlMRnV1dZJGxrgMd4OheY3hbq0IxzrNQdhMKQOoGJIKgKgu+6LbsJns7mD929/+5sXMvbpS6Ypac36HexgQKiubzdoVsPl83ou5SwfCu33cHefheR3Nzc2S6NZWm/lcheeilLu73F0df+rUKS9m7lAvt/uclgqAqEgqAKIiqQCIKvWYilmmGx6I+9FHH9lyV1eX/0NqRn5MeM4pYynVV1NTY/vR4ZJt9xzacOrRXYIfnlm8cOFCSeWnHjGxhoaG7El+4ZiKGRuRSutu7969trxz504vZsZiyu0+p6UCICqSCoCouEsZ1OskxV3KACYFuj8AoiKpAIgq1ZSye+duaPv27Vf8MNylXB0tLS2Ju5Uipu7ubvX09FCvVVDu83qlyt2RnSqpuHfuhty7lPG/pb29XU8++eSEvPfvf//7CXlfXFq5z+uVuvHGG8eMpUoq27dvJ3kA/yPcz2u5CZnwM32lkzeMqQCIiqQCICqSCoCoLvuQplhM/63cwA+AiRN7ASwtFQBRkVQARFWRpJIkyZj/w+S0fv16rV+/vuSsDkx+tFQAREVSARAVSQVAVBWZUnaXATOOAkxutFQAREVSARBVtO4P3Zr/39avX1/tR8CPBC0VAFGRVABERVIBEFW0MRWmjSeHDRs2eF+//vrrY76WcZT/HbFPdyuHlgqAqEgqAKLi2lNQr5MU154CmBTo/gCIiqQCICqSCoCoSCoAoiKpAIiKpAIgKpIKgKhIKgCiIqkAiOr/AJ/8sdM/QP5ZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 24 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "# plot first few filters\n",
    "n_filters, ix = 8, 1\n",
    "\n",
    "for i in range(n_filters):\n",
    "    # get the filter\n",
    "    f = filters[:, :, :, i]\n",
    "    # plot each channel separately\n",
    "    for j in range(3):\n",
    "        # specify subplot and turn of axis\n",
    "#         plt.figure(figsize=(5,20)) \n",
    "        ax = pyplot.subplot(n_filters, 3, ix)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        # plot filter channel in grayscale\n",
    "        pyplot.imshow(f[:, :, j], cmap='gray')\n",
    "        ix += 1\n",
    "# show the figure\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_1_5:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (256, 256, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_1_6:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (256, 256, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1418 predict_step\n        return self(x, training=False)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer pad is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [256, 256, 3]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-d919c210c4d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Extract train and test features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprojection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprojection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1418 predict_step\n        return self(x, training=False)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /gpfs/users/liashuhamy/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer pad is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [256, 256, 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "tic = time.time()\n",
    "# Extract train and test features\n",
    "train_features = projection.predict(X_train)\n",
    "print(train_features.shape)\n",
    "test_features = projection.predict(X_test)\n",
    "print(time.time() - tic)\n",
    "\n",
    "print( test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# train_features1 = scaler.fit_transform(train_features)\n",
    "# test_features1 = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping to prevent overfitting\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=2, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linear_model = get_linear_model(256)\n",
    "linear_model.summary()\n",
    "linear_model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"],\n",
    "                     optimizer=\"adam\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = linear_model.fit(train_features, y_train_enc,\n",
    "                 validation_data=(test_features, y_test_enc),\n",
    "                 batch_size=64,\n",
    "                 epochs=30,\n",
    "                 callbacks=[es])\n",
    "plot_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, SGDClassifier\n",
    "reg = SGDClassifier().fit(train_features, y_train)\n",
    "reg.score(test_features, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=100).fit(train_features, y_train)\n",
    "clf.score(test_features, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
